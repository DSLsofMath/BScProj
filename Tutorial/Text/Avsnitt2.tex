\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage[T1]{fontenc}
\usepackage[swedish]{babel}
\usepackage[makeroom]{cancel}
\usepackage{amssymb, amsmath, lmodern, units, icomma, color, graphicx, bbm, hyperref, pdfpages, csquotes, listings}
\usepackage{minted}
\usepackage[backend=biber]{biblatex}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}


\title{Avsnitt 2 \\
\large Om LTI-system, stegsvar, impulssvar, faltning och annat matnyttigt}
\author{ }
\date{}

\begin{document}

\maketitle

\section{Vad menas med LTI-system?}
$$x(t) \rightarrow \framebox[1.2\width]{\textbf{LTI-system}} \rightarrow y(t) $$

Linjära tidsinvarianta system, eller LTI-system, är logiskt nog system som är
linjära och tidsinvarianta. Hurra för logik! Men för att den förklaringen ska
bli lite mer begriplig kan det ju vara bra att reda ut vad som menas med
“Linjär” och “Tidsinvariant”. Med ett linjärt system menar man, lite
förenklat uttryckt, ett system där man kan separera signalerna i sina
beståndsdelar. Ett tidsinvariant system är ett system vars egenskaper inte
ändras med tiden. En mer detaljerad beskrivning av dessa egenskaper kommer
senare men inledelsevis kan vi konstatera att ett LTI-system är ett system
med fina konsekventa ekvationer som är relativt enkla att räkna på. Så
rysligt praktiskt!

%------------------------------------------------------------------
%*Ev Bild på några olika linjära ekv. i kordinatsystem
\newline
LTI-system är något man använder sig av väldigt mycket inom signallära. Även
system som egentligen inte är linjära och tidsinvarianta approximeras ofta
till LTI-system, eftersom det är så mycket trevligare att räkna på
LTI-system. Alla älskar LTI-system! Åtminstone jämfört med andra system som
ändrar sig hela tiden och är odrägliga att försöka räkna på, usch och fy!

\section{Egenskaper hos LTI-system}

LTI-system har många trevliga egenskaper som gör att deras vänner gillar
dem och deras fiender avundas dem. Nu ska vi ta en kik på ett par av de viktigaste egenskaperna.


\subsection{Linjäritet}
För att ett system ska vara linjärt måste det uppfylla
superpositionsprincipen, vilket innebär att det är både  additativt och
homogent för er som tycker om att svänga er med fina ord.

I ett system som är additativt kan man dela upp insignalen i mindre
komponenter och kika på dessa komponenters utsignaler och dessa kan sedan
kombineras till hela insignalens utsignal. Mycket praktiskt!
$$F(x_{1}+x_{2}) = F(x_{1}) + F(x_{2})$$
$$x_{1}(t) + x_{2}(t) \rightarrow \framebox[1.2\width]{\textbf{Additativt system}} \rightarrow \mathrm{y_{1}(t) + y_{2}(t)}$$

I ett homogent system kan man bryta ut skalningsfaktorer ifrån insignalen och skala om utsignalen med dessa istället.
$$F(ax) = aF(x), \quad \mbox{$a$ är en konstant}$$
$$a x(t) \rightarrow \framebox[1.2\width]{\textbf{Homogent system}} \rightarrow ay(t)$$

Det är dessa två egenskaper som tillsammans utgör superpositionsprincipen.
Superpositionsprincipen gör att man kan se insignalerna, och dess
komponenter, till ett linjärt system som så grundläggande signaler som
möjligt och sen bara skalar och kombinerar utsignalerna de genererar.
Kan man visa att
ett system uppfyller superpositionsprincipen har man visat att det är
linjärt.
Hur vet man då om systemet uppfyller superpositionsprincipen? Jo, säg att vi har två signaler $x_1$ och $x_2$.

Om systemet uppfyller superpositionsprincipen gäller då att:

$$F(a x_{1}+b x_{2}) = a F(x_{1}) + b F(x_{2}), \quad
\mbox{ a och b är konstanter}
$$
$$a x_{1}(t)+b x_{2}(t) \rightarrow \framebox[1.2\width]{\textbf{SuperPos. system}} \rightarrow \mathrm{a y_{1}(t)+b y_{2}(t)}
$$

Och därmed är systemet linjärt!

\textbf{Övning 1:} Här följer ett kodskelett till en funktion som undersöker om ett
system är Linjärt. Fyll i det som saknas.

\begin{minted}{haskell}
isLinearDisc :: DiscTimeFun -- ^ Insignal 1
            -> DiscTimeFun -- ^ Insignal 2
            -> DiscSystem  -- ^ System
            -> Double -- ^ Skalningsfaktor 1
            -> Double -- ^ Skalningsfaktor 2
            -> DiscTime -- ^ Tid då vi mäter
            -> Bool
isLinearDisc x0 x1 sys a b t = undefined
\end{minted}

\textbf{Tips!} Du kommer behöva skala om signalerna, kolla i {\tt Signals.hs} efter en
lämplig funktion.

\subsection{Tidsinvarians}
Med hur är det då med tidsinvarians? Vad är det för egenskaper som gäller
där? Jo, ett system är tidsinvariant om en tidsförskjutning i insignalen ger samma tidsförskjutning i utsignalen. Alltså:

$$x(t-c) \rightarrow \framebox[1.2\width]{\textbf{Tidsinvariant system}} \rightarrow y(t-c) $$
  $$\mbox{där c är en reel konstant}$$

\textbf{Övning 2:} Implementera en funktion som undersöker om ett system är tidsinvariant i kontinuerlig tid enligt följande:

\begin{minted}{haskell}
isTimeInvCont :: ContTimeFun -> ContSystem ->
                        ContTime -> ContTime -> Bool

\end{minted}

\textbf{Tips!} Använd dig av följande funktion för tidsskift:

\begin{minted}{haskell}
timeShift :: Num time => Signal time val
          -> time -> time -> Signal time val
timeShift sig o t = sig (t - o)
\end{minted}

\textbf{Övning 3:} Implementera en funktion som undersöker om ett system är ett LTI-system. Använd dig av funktionerna från övning 1 och 2.

\textbf{Test:}

% **TODO: Testen ovan handlar om att beskriva om ett _system_ är
% linjärt, inte om en signal (som funktionerna ned) är linjär. Ett
% "system" i den här kontexten är en andra ordningens funktion -
% exempelvis: snitt f = \t -> (f t + f (t-1)) / 2

Använd funktionen från övning 3 för att undersöka om följande funktioner är linjära:
\begin{enumerate}
\item $\pi + 2\;t$
\item $\sin(2\;t)$
\item $x/2$
\item $\cos(2^t)$
\end{enumerate}

\section{Stegsvar och Impulsvar}

Impulssvar och stegsvar är härligt nog ganska precis vad de låter som. Ett
systems impulssvar är den utsignal man får när man skickar in en enhetsimpuls
som insignal till systemet och stegsvar är systemets utsignal när man skickar
in ett enhetssteg som insignal. Kommer du inte ihåg vad en enhetsimpuls eller
ett enhetssteg är för något så titta tillbaka på kapitlet som heter
Introduktion. I korthet så är en enhetsimpuls en signal som är definierad som
0 vid alla tidpunkter utom tiden 0 och enhetssteg är en signal definierad som
0 för negativa tidpunkter och 1 för positiva tidpunkter.

$$
u[n] = \begin{cases}
    0, \quad n < 0 \\
    1, \quad annars
        \end{cases}
\quad \quad \quad
u(t) =
    \begin{cases}
    0, \quad t < 0 \\
    1, \quad t \geq 0
    \end{cases},
$$
$$
\delta[n] =
    \begin{cases}
    1, \quad t = 0 \\
    0, \quad annars
    \end{cases}
\quad \quad \quad
\delta(t) =
    \begin{cases}
    1, \quad t = 0 \\
    0, \quad annars
    \end{cases}
$$

Impuls- och stegsvar används ofta för att undersöka hur ett system beter sig.
Hur systemet svarar på några standardsignaler, som enhetsimpulser och
enhetssteg, kan vara till hjälp för att få en grundläggande bild av hur
systemet fungerar. Impulssvaret kan även användas för att beräkna det som
kallas för systemets överföringsfunktion, men mer om det senare!
\newline
Impulssvar brukar betecknas med $h(t)$ för kontinuerlig tid och $h[n]$ för diskret tid.
Det här:
$$\textbf{enhetsimpuls} \rightarrow \framebox[1.2\width]{\textbf{LTI-system}} \rightarrow \textbf{impulssvar} $$

kan alltså skrivas så här:
$$\delta (t) \rightarrow \framebox[1.2\width]{\textbf{LTI-system}} \rightarrow h(t) $$

Kortfattat och fint!
\newline

Just för LTI-system så har man särskild nytta av impulssvaret. Det är
nämligen så att man kan beräkna ett LTI-systems utsignal genom faltning av insignalen med impulssvaret.
$$ y(t)=x(t)*h(t),$$
utsignalen kan fås genom faltning av insignalen med impulssvaret
Detta för oss genast till frågan: Vad tusan är faltning för något?

\section{Faltning}

Faltning av en signal f(t) med en signal g(t) skrivs: $f(t)*g(t)$, dvs det
skrivs precis som man ofta skriver multiplikation. Är inte det väldigt dumt
undrar ni då? Svaret är ja. Ja, det är jättedumt. Dessvärre så är det så
standarden ser ut. Var därför väldigt noga med att inte blanda ihop faltning
och multiplikation, det har orsakat många pinsamma misstag genom tiderna.
\newline

Ett tips när man beskriver signaler är att skriva multiplikation
av signalerna $x_1$ och $x_2$ som \emph{$x_1$ $x_2$}, alltså att man skriver ihop dem,
och faltningen av $x_1$ och $x_2$ betecknas $x_1 * x_2$. Men se upp för att det
kan blir syntaxkrockar i programmeringssammanhang, då det är standard att
använda $*$ för multiplikation där, medans faltning ofta betecknas med \emph{conv}, från engelskans convolution, eller liknande.


Faltning ses ofta som en operator som är svår att förstå sig på eftersom
det kan vara lite besvärligt att få en intuitiv känsla för hur och varför
den fungerar. Men vi tar och benar ut den i stora drag i alla fall.
Faltning har följande definition i det kontinuerliga fallet:

$$ f(t) * g(t) = \int_{0}^t  f(s) g(t-s) ds $$

Lagar om faltning! En tumregel är att den i princip följer samma lagar som multiplikation!
$$f(t) * (a g(t) + b h(t) ) = a(f(t) * g(t)) + b(f(t) * h(t))$$ % Linjaritet
$$f(t) * g(t) = g(t) * f(t) $$ %Kommutative
$$f(t) * (g(t) * h(t)) = (f(t) * g(t)) * h(t) $$ %Associative
Där a och b är konstanter och f, g och h är funktioner. Det borde även nämnas att följande lagar innefattar även att

$$ f(t) * g(t) = \int_{0}^t  f(s) g(t-s) ds = \int_{0}^t  f(t-s) g(s) ds = g(t) * f(t) $$

Så oroa er inte om integrandens ordning! Det finns även en diskret faltning och även denna följer samma lagar som det kontinuerliga fallet.

%------------------Vi har kvar detta ifall vi ska introducera periodisk faltning. Annars kan gruppen ta bort det kommenterade.
%Denna kommer ifrån en definition där det inte finns negativa talserie det vill säga $a_{-1}$
%$$a_n * b_n = \sum_{k=0}^{N-1} a_k b_{[n-k]}, \quad [n-k] =
%\begin{cases}
%n-k, \quad  \; n \geq k \\
%n-k+N, \quad  n < k
%\end{cases}
%$$
%Den konstiga notationen $[n-k]$ finns för att talserierna $a_n$ och $b_n$ inte tar negativa index. Alltså för att motverka detta så adderas N då k > n. %kanske ska skrivas lite mer utförligt.
%kanske tydligare om vi istället skriver
%$$ a[n] * b[n] = (\sum_{k=0}^{n} a[k] b[n-k]) +  \sum_{k=n+1}^{N-1} a[k] b[n-k]

%Här är den allmänna definitionen
$$a[n] * b[n] = \sum_{k=-\infty}^{\infty} a[k] b[n-k]$$
Eller om det finns en finit antal värden i talserien. %Vi säger 2N+1 tal
$$a[n] * b[n] = \sum_{k=-N}^{N} a[k] b[n-k]$$
%Problemet jag har med denna definition är ju att det känns som om den stiger ifrån den definierade mängden... Men den borde vara korrekt.


%En exempel som kan tas upp är sampling. Vi har en signal vars funktions uttryck är okänd men dess plottade kurva är känd. (Det vill säga det finns en bild på kurvan). Systemresponsen är känd och vi vill få fram utsignalens värden. 


%Detta är en kladdig förklaring på varför det blir en faltning i ett LTI system. Kan tas bort.
%------------------------------------------------------------
%I princip, om vi betraktar insignalen som en summa av tidskiftade impulser(multiplicerad med konstanter (vikter) $c_k$), så är utsignalen en summa av tidskiftade impulssvar. Jag kan ge en matematiskt förklaring till detta via ett exempel.
%Min uppfattning av bokens exempel.
%Givet en insignal x(t). Om vi samplar insignalen över ett viss tidsinterval så kan den approximeras som summa en summa av impulser.
%$$x(t) \approx x[t] = \sum c_k \delta (t-\Delta k)$$ \Delta.
%Vilket ger utsignalen
%$$y[t] = \sum c_k h(t-\Delta k) \Delta$$
%Där $\Delta$ är tidsskillnaden mellan varje sampling och $\delta$ implicerar en impulsfunktionen (typ) vars längd beror på tidskillnaden.
%Om vi nu ser talföljden $c_k$ som en funktion av tid f(t), låter $\Delta -> 0$ så kan summan betraktas som en integral och impulsfunktionen byts från en diskret till kontinuerlig. Det vill säga
%$$x[t] = \sum c_k \delta (t-\Delta k)$ \Delta -> \int f(\tau) \delta(t-\tau) d \tau = f(t)  $$
%Om ni kommer ihåg impulsfunktionens egenskap att $\int f(\tau) \delta(t-\tau) d \tau = f(t) = x(t)$.
%Utsignalen blir då följande
%$$y[t] = \sum c_k h(t-\Delta k) \Delta -> \int f(tau) h(t-\tau) d \tau $$
%Därav relationen mellan dessa två blir.
%$$y(t) = \int x(\tau) h(t-\tau) d \tau = x(t) * h(t) $$
%Vilket förklarar varför det blir en faltning i en LTI-system.

Så hur hör allt detta tillsammans med LTI-system? En tolkning av faltning
är en kontinuerlig superposition av f (eller g). Men om man inte vill gå in
i för djupa detaljer så är faltning i ett nötskal, inom detta området,
systemets respons till en insignal. Det vill säga givet insignalen $x(t)$
och system responsen $h(t)$, systemets utsignal $y(t)$ kan beräknas från
$$y(t) = x(t) * h(t) $$
Det vill säga utsignalen fås av en faltning mellan impulssvaret och insignalen. Om du inte vill gå in djupare på teorin så får du helt enkelt acceptera det.
\\

\textbf{Övning 4:}
Här följer ett kodskelett till en implementering av diskret faltning. Fyll i det som saknas.
\begin{minted}{haskell}
discConvolution :: DiscTimeFun -- ^ Signal 1
                -> DiscTimeFun -- ^ Signal 2
                -> DiscTime -- ^ Avstånd från 0,
                -- intervallet sträcker sig från -limit .. limit
                -> DiscTimeFun -- ^ Returnfunktion
discConvolution s0 s1 limit = undefined
\end{minted}
En kanske enklare metod att beräkna faltningar presenteras i Fourier kapitlet.
\newpage

\section{Sammanfattning}
Gratulerar! Du har nu lärt dig
\begin{itemize}
\item Vad LTI-system är för något
\item Hur man undersöker eller bevisar om ett system är ett LTI-system genom att kontrollera superposition och tidsinvarians
\item Hur man implementerar och använder funktioner för superposition och tidsinvarians med funktionell programmering och DSL.
\item Vad impulssvar och stegsvar är
\item Lite om faltning
\item Hur man kan beräkna ett LTI-systems utsignal genom faltning av insignalen med impulssvaret
\end{itemize}
Passa nu på att ge dig själv en välförtjänt klapp på axeln innan du går vidare till nästa kapitel!

%Bilderna i detta kapitel är gjorda i:
%\begin{itemize}
%\item MATLAB: Figur
%\item FOOPLOT: Figur
%\end{itemize}

\section{Lösningar}

Övning 1
\begin{minted}{haskell}
isLinearDisc :: DiscTimeFun -- ^ Insignal 1
            -> DiscTimeFun -- ^ Insignal 2
            -> DiscSystem  -- ^ System
            -> Double -- ^ Skalningsfaktor 1
            -> Double -- ^ Skalningsfaktor 2
            -> DiscTime -- ^ Tid då vi mäter
            -> Bool
isLinearDisc x0 x1 sys a b t = testAt (y0' + y1') (y0 `scale` a + y1 `scale` b) t
    where y0  = discOutSignal sys x0
          y1  = discOutSignal sys x1
          y0' = discOutSignal sys (x0 `scale` a)
          y1' = discOutSignal sys (x1 `scale` b)
          testAt a b t = a t ~= b t
\end{minted}

Övning 2
\begin{minted}{haskell}
isTimeInvCont :: ContTimeFun -> ContSystem -> ContTime -> ContTime -> Bool
isTimeInvCont x sys t c = y' t ~= (timeShift y c) t
    where x' = timeShift x c
          y  = contOutSignal sys x
          y' = contOutSignal sys x'
\end{minted}{haskell}

Övning 4
\begin{minted}{haskell}
discConvolution :: DiscTimeFun -- ^ Signal 1
                -> DiscTimeFun -- ^ Signal 2
                -> DiscTime -- ^ Interval length -M start
                -> DiscTimeFun -- ^ Returnfunktion
discConvolution s0 s1 interval = sum $ map conv points
    where points = [from .. interval]
          from = negate interval
          conv n m = (s0 n * (s1 (n-m)))
\end{minted}
\end{document}
